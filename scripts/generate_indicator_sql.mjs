import { promises as fs } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const projectRoot = path.resolve(__dirname, '..');

const YEARS = [2023, 2024, 2025];
const DATABASES = ['e04dm_inclusion_europe', 'e04dm_inclusion_dev'];
const DATASET_DIR = path.join(projectRoot, 'public', 'datasets');
const OUTPUT_DIR = path.join(projectRoot, 'sql', 'data');

const wrapBase64 = (payload, width = 120) => {
  const chars = [];
  for (let i = 0; i < payload.length; i += width) {
    chars.push(payload.slice(i, i + width));
  }
  return chars.join('\n');
};

const buildSql = ({ dbName, year, base64Payload }) => `-- Auto-generated by scripts/generate_indicator_sql.mjs
-- Source: public/datasets/inclusion-indicators-${year}.json
USE ${dbName};

INSERT INTO inclusion_indicators (year, dataset)
VALUES
  (
    ${year},
    CAST(
      FROM_BASE64('${base64Payload}') AS JSON
    )
  )
ON DUPLICATE KEY UPDATE
  dataset = VALUES(dataset),
  updated_at = CURRENT_TIMESTAMP;
`;

const ensureDir = async (dirPath) => {
  await fs.mkdir(dirPath, { recursive: true });
};

const main = async () => {
  await ensureDir(OUTPUT_DIR);

  for (const year of YEARS) {
    const datasetPath = path.join(DATASET_DIR, `inclusion-indicators-${year}.json`);
    const raw = await fs.readFile(datasetPath, 'utf8');
    const json = JSON.stringify(JSON.parse(raw));
    const base64 = Buffer.from(json, 'utf8').toString('base64');
    const wrapped = wrapBase64(base64);

    await Promise.all(
      DATABASES.map(async (dbName) => {
        const sql = buildSql({ dbName, year, base64Payload: wrapped });
        const fileName = `${dbName}_inclusion_indicators_${year}.sql`;
        const outPath = path.join(OUTPUT_DIR, fileName);
        await fs.writeFile(outPath, sql, 'utf8');
      })
    );
  }

  console.log('SQL files generated in sql/data');
};

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
